#!/usr/bin/env python3
"""
Module 3: AI Analysis Core
–ê–Ω–∞–ª–∏–∑ —Å–∫—Ä—ã—Ç—ã—Ö —Å–º—ã—Å–ª–æ–≤ –∏ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø–æ–º–æ—â—å—é AI
"""

import json
import logging
from typing import Dict, Optional
import openai
from openai import OpenAI

from config import OPENAI_API_KEY, AI_SYSTEM_PROMPT

logger = logging.getLogger(__name__)

class AIAnalyst:
    """–ö–ª–∞—Å—Å –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        if not OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        
        self.client = OpenAI(api_key=OPENAI_API_KEY)
        
    def analyze_news(self, news: Dict) -> Optional[Dict]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
        try:
            logger.info(f"ü§ñ –ù–∞—á–∏–Ω–∞–µ–º AI –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏: {news.get('title', 'Unknown')[:100]}...")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            user_prompt = self._create_user_prompt(news)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ AI
            analysis_result = self._call_openai_api(user_prompt)
            
            if not analysis_result:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –æ—Ç AI")
                return None
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            parsed_result = self._parse_ai_response(analysis_result)
            
            if not parsed_result:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç AI")
                return None
            
            logger.info("‚úÖ AI –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω")
            return parsed_result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ AI –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
            return None
    
    def _create_user_prompt(self, news: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º—Ç–∞ –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞"""
        title = news.get('title', '')
        description = news.get('description', '')
        link = news.get('link', '')
        source = news.get('source', '')
        date = news.get('date')
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
        date_str = ""
        if date:
            date_str = f"–î–∞—Ç–∞: {date.strftime('%d.%m.%Y')}"
        
        user_prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É –Ω–æ–≤–æ—Å—Ç—å:

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–û–ø–∏—Å–∞–Ω–∏–µ: {description}
–ò—Å—Ç–æ—á–Ω–∏–∫: {source}
{date_str}
–°—Å—ã–ª–∫–∞: {link}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–∫—Ä—ã—Ç—ã–π —Å–º—ã—Å–ª —ç—Ç–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –∏ –µ—ë –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è.
"""
        
        return user_prompt.strip()
    
    def _call_openai_api(self, user_prompt: str) -> Optional[str]:
        """–í—ã–∑–æ–≤ OpenAI API"""
        try:
            logger.info("üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API...")
            
            response = self.client.chat.completions.create(
                model="gpt-4o",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-4o –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                messages=[
                    {"role": "system", "content": AI_SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,  # –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å—é –∏ —Ç–æ—á–Ω–æ—Å—Ç—å—é
                max_tokens=2000,  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                timeout=60  # –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            )
            
            if response.choices and len(response.choices) > 0:
                result = response.choices[0].message.content
                logger.info("‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç OpenAI API")
                return result
            else:
                logger.error("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI API")
                return None
                
        except openai.RateLimitError:
            logger.error("‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI API")
            return None
        except openai.APIError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI API: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI API: {str(e)}")
            return None
    
    def _parse_ai_response(self, response: str) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI"""
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            cleaned_response = self._clean_json_response(response)
            
            # –ü–∞—Ä—Å–∏–º JSON
            parsed_data = json.loads(cleaned_response)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞
            required_fields = ['hidden_meanings', 'market_impact', 'people_impact', 'sector_analysis', 'simple_analogy']
            
            for field in required_fields:
                if field not in parsed_data:
                    logger.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {field}")
                    parsed_data[field] = "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"
            
            return parsed_data
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {str(e)}")
            logger.error(f"üìÑ –ü–æ–ª—É—á–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {response[:500]}...")
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            return self._extract_info_from_text(response)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ—Ç–≤–µ—Ç–∞ AI: {str(e)}")
            return None
    
    def _clean_json_response(self, response: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ JSON –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
        start_marker = '{'
        end_marker = '}'
        
        start_idx = response.find(start_marker)
        if start_idx == -1:
            raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
        
        # –ò—â–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É —Å –∫–æ–Ω—Ü–∞
        end_idx = response.rfind(end_marker)
        if end_idx == -1:
            raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
        
        json_str = response[start_idx:end_idx + 1]
        
        # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ escape-—Å–∏–º–≤–æ–ª—ã
        json_str = json_str.replace('\\n', ' ').replace('\\t', ' ')
        
        return json_str
    
    def _extract_info_from_text(self, text: str) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ JSON –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å"""
        logger.info("üîÑ –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞...")
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        result = {
            'hidden_meanings': ["–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"],
            'market_impact': "–í–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä—ã–Ω–∫–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ",
            'people_impact': "–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ª—é–¥–µ–π –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ",
            'sector_analysis': "–ê–Ω–∞–ª–∏–∑ —Å–µ–∫—Ç–æ—Ä–æ–≤ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω",
            'simple_analogy': "–ê–Ω–∞–ª–æ–≥–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        }
        
        # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –≤ —Ç–µ–∫—Å—Ç–µ
        text_lower = text.lower()
        
        # –ò—â–µ–º —Å–∫—Ä—ã—Ç—ã–µ —Å–º—ã—Å–ª—ã
        if '—Å–∫—Ä—ã—Ç—ã–π' in text_lower or '–ø–æ–¥—Ç–µ–∫—Å—Ç' in text_lower or '–Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ' in text_lower:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —ç—Ç–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
            sentences = text.split('.')
            hidden_sentences = [s.strip() for s in sentences if any(word in s.lower() for word in ['—Å–∫—Ä—ã—Ç—ã–π', '–ø–æ–¥—Ç–µ–∫—Å—Ç', '–Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ'])]
            if hidden_sentences:
                result['hidden_meanings'] = hidden_sentences[:3]
        
        # –ò—â–µ–º –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä—ã–Ω–∫–∏
        if '—Ä—ã–Ω–æ–∫' in text_lower or '–∞–∫—Ü–∏–∏' in text_lower or '–æ–±–ª–∏–≥–∞—Ü–∏–∏' in text_lower:
            market_sentences = [s.strip() for s in text.split('.') if any(word in s.lower() for word in ['—Ä—ã–Ω–æ–∫', '–∞–∫—Ü–∏–∏', '–æ–±–ª–∏–≥–∞—Ü–∏–∏', '–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç'])]
            if market_sentences:
                result['market_impact'] = '. '.join(market_sentences[:2])
        
        # –ò—â–µ–º –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –ª—é–¥–µ–π
        if '–ª—é–¥–∏' in text_lower or '–Ω–∞—Å–µ–ª–µ–Ω–∏–µ' in text_lower or '–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–∏' in text_lower:
            people_sentences = [s.strip() for s in text.split('.') if any(word in s.lower() for word in ['–ª—é–¥–∏', '–Ω–∞—Å–µ–ª–µ–Ω–∏–µ', '–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–∏', '–≥—Ä–∞–∂–¥–∞–Ω–µ'])]
            if people_sentences:
                result['people_impact'] = '. '.join(people_sentences[:2])
        
        return result
